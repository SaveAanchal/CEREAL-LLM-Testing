{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aJlBlYIACspG",
        "outputId": "b411b56d-2210-42e8-82f9-ca1940d38368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: gpytorch==1.12 in /usr/local/lib/python3.11/dist-packages (1.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.12) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.12) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.12) (1.13.1)\n",
            "Requirement already satisfied: linear-operator>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.12) (0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (from linear-operator>=0.5.2->gpytorch==1.12) (0.2.38)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.12) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.12) (3.5.0)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping->linear-operator>=0.5.2->gpytorch==1.12) (0.1.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading in model...\n",
            "    lam_L.pt file already loaded...\n",
            "    Loading complete!\n",
            "The current thresholds for matching files are: 0.1 degree for angle of attack, 0.01 for mach number, and 1e5 for reynolds number.\n",
            "Do you want to change the thresholds? (yes/no): no\n",
            "Enter your query (or type 'exit' to quit): data for naca 123, mach 3, re 4, aoa 4\n",
            "BERT raw output for Airfoil Name: naca 123,\n",
            "BERT raw output for Angle of Attack: aoa 4\n",
            "BERT raw output for Mach Number: mach 3,\n",
            "BERT raw output for Reynolds Number: re 4,\n",
            "Extracted Parameters: {'Airfoil Name': 'naca 123', 'Angle of Attack': 4.0, 'Mach Number': 3.0, 'Reynolds Number': 4.0}\n",
            "Detected airfoil: naca 123\n",
            "Error fetching airfoil list from GitHub.\n",
            "Using LAM to predict distribution.\n",
            "predicting...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid NACA 4-digit or 5-digit code.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-2839b88e999d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mprocess_user_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-2839b88e999d>\u001b[0m in \u001b[0;36mprocess_user_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mairfoil_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NACA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using LAM to predict distribution.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0mpredict_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mairfoil_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Airfoil data not found. Enter a csv file of coordinates for prediction.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-2839b88e999d>\u001b[0m in \u001b[0;36mpredict_distribution\u001b[0;34m(query_params, coordinates_file, lam_model, use_gpu)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mmach_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Mach Number\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mreynolds_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Reynolds Number\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mairfoil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam_adapt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_of_attack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmach_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo_num_points_per_surface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mairfoil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_coeff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lam_adapt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, airfoil_input, alpha, mach, num_auto_points, manual_points, use_gpu)\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_naca5digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mairfoil_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid NACA 4-digit or 5-digit code.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid input airfoil. Please use a csv file or a NACA 4-digit airfoil.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid NACA 4-digit or 5-digit code."
          ]
        }
      ],
      "source": [
        "!pip install transformers pandas torch gpytorch==1.12 requests\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import torch\n",
        "import requests\n",
        "import lam_adapt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering, pipeline\n",
        "\n",
        "search_url = \"https://api.github.com/repos/hwlee924/Large-Airfoil-Model/contents/ASPIRE/Airfoils\"\n",
        "headers = {\"Authorization\": \"token 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\"}\n",
        "\n",
        "\"\"\"\n",
        "loads the BERT model, uses gpu if available\n",
        "\"\"\"\n",
        "def load_bert_pipeline():\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
        "    model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0 if device == \"cuda\" else -1)\n",
        "    return qa_pipeline\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "loads the LAM model, uses gpu if available\n",
        "\"\"\"\n",
        "\n",
        "def load_lam_model():\n",
        "    notebook_dir = Path().resolve()\n",
        "    os.chdir(notebook_dir)\n",
        "    use_gpu = True if torch.cuda.is_available() else False\n",
        "    model, likelihood = lam_adapt.unpack_model(use_gpu=use_gpu)\n",
        "    return model, use_gpu\n",
        "\n",
        "\"\"\"\n",
        "uses bert to extract data from the user query\n",
        "query: user input, qa_pipeline: the BERT model\n",
        "\"\"\"\n",
        "def extract_query_parameters(query, qa_pipeline):\n",
        "\n",
        "    #background context for the model to use when answering questions\n",
        "    structured_context = f\"\"\"\n",
        "    The user wants to extract aerodynamic data.\n",
        "    The airfoil name, angle of attack, Mach number, and Reynolds number are mentioned in the query.\n",
        "    Extract these values from the following user request: {query}\n",
        "    \"\"\"\n",
        "\n",
        "    #questions for the model to find the various values in the user's prompt\n",
        "    parameters = {\n",
        "        \"Airfoil Name\": \"What is the airfoil name?\",\n",
        "        \"Angle of Attack\": \"What is the angle of attack in degrees, allowing for optional negative degrees? It may be written as aoa or a\",\n",
        "        \"Mach Number\": \"What is the Mach number? It may be written as m or mach\",\n",
        "        \"Reynolds Number\": \"What is the Reynolds number or re? It may be written as reynolds or re\"\n",
        "    }\n",
        "\n",
        "    extracted_parameters = {}\n",
        "\n",
        "    for param, question in parameters.items():\n",
        "        try:\n",
        "            #uses BERT to extract the data from the query\n",
        "            response = qa_pipeline(question=question, context=structured_context)\n",
        "            extracted_value = response[\"answer\"]\n",
        "\n",
        "            print(f\"BERT raw output for {param}: {extracted_value}\")\n",
        "\n",
        "            #remove any commas from the extracted data\n",
        "            extracted_value = extracted_value.replace(\",\", \"\").strip()\n",
        "\n",
        "            if param == \"Airfoil Name\":\n",
        "                extracted_parameters[param] = extracted_value\n",
        "                if \"mach\" in extracted_value.lower():\n",
        "                    extracted_parameters[param] = None\n",
        "                if \"reynolds\" in extracted_value.lower():\n",
        "                    extracted_parameters[param] = None\n",
        "                if \"angle of attack\" in extracted_value.lower() or \"aoa\" in extracted_value.lower() or \"degrees\" in extracted_value.lower():\n",
        "                    extracted_parameters[param] = None\n",
        "            else:\n",
        "                #extract only the numerical values\n",
        "                match = re.search(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", extracted_value)\n",
        "                extracted_parameters[param] = float(match.group(0)) if match else None\n",
        "\n",
        "        except Exception as e:\n",
        "            #handle errors if unable to extract value\n",
        "            print(f\"Error extracting {param}: {e}\")\n",
        "            extracted_parameters[param] = None\n",
        "\n",
        "    print(f\"Extracted Parameters: {extracted_parameters}\")\n",
        "    return extracted_parameters\n",
        "\n",
        "\"\"\"\n",
        "returns coordinates file for a specific airfoil\n",
        "\"\"\"\n",
        "\n",
        "def get_airfoil_geometry(file_dict, subfolder):\n",
        "    if subfolder is None or subfolder not in file_dict: #use root if no subfolder\n",
        "        subfolder = \"root\"\n",
        "    for filename, url in file_dict[subfolder].items():\n",
        "        if filename.endswith(\"_coordinates.csv\") or filename.endswith(\"_coordinates_.csv\"): #find coordinates file\n",
        "            response = requests.get(url, headers=headers)\n",
        "            if response.status_code != 200:\n",
        "                print(\"Error fetching airfoil coordinates file from GitHub.\")\n",
        "                return None\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"Using coordinates file: {filename}\")\n",
        "            return filename\n",
        "    return None\n",
        "\n",
        "\"\"\"\n",
        "fetches the list of available airfoil data files from GitHub given the airfoil name\n",
        "\"\"\"\n",
        "def get_airfoil_filenames(airfoil_name):\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        #print(response.status_code)\n",
        "        print(\"Error fetching airfoil list from GitHub.\")\n",
        "        return None\n",
        "\n",
        "    airfoil_files = response.json()\n",
        "    available_airfoils = {entry['name']: entry['url'] for entry in airfoil_files if entry['type'] == 'dir'} #create dictionary of all folders\n",
        "    matching_airfoils = [name for name in available_airfoils.keys() if airfoil_name.lower() in name.lower()] #checks for a match with the airfoil folder\n",
        "\n",
        "    if not matching_airfoils:\n",
        "        return None\n",
        "\n",
        "    selected_airfoil = matching_airfoils[0]\n",
        "    print(f\"Using airfoil: {selected_airfoil}\")\n",
        "\n",
        "    airfoil_url = available_airfoils[selected_airfoil]\n",
        "    response = requests.get(airfoil_url, headers=headers) #gets files for airfoil\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error fetching files for airfoil '{selected_airfoil}'.\")\n",
        "        return None\n",
        "\n",
        "    airfoil_data_files = response.json()\n",
        "    subfolder_urls = {entry['name']: entry['url'] for entry in airfoil_data_files if entry['type'] == 'dir'} #checks for subfolders\n",
        "    file_dict = {}\n",
        "\n",
        "    if subfolder_urls:\n",
        "        for subfolder_name, subfolder_url in subfolder_urls.items():\n",
        "            subfolder_response = requests.get(subfolder_url, headers=headers)\n",
        "            if subfolder_response.status_code != 200:\n",
        "                continue\n",
        "            subfolder_files = subfolder_response.json()\n",
        "            file_dict[subfolder_name] = {entry['name']: entry['download_url'] for entry in subfolder_files if entry['type'] == 'file'} #adds subfolders to dictionary\n",
        "\n",
        "    if not file_dict:\n",
        "        file_dict[\"root\"] = {entry['name']: entry['download_url'] for entry in airfoil_data_files if entry['type'] == 'file'} #subfolder is root if no subfolders\n",
        "\n",
        "    return file_dict\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "uses regex to extract values from the given filename\n",
        "\"\"\"\n",
        "def extract_metadata_from_filename(filename):\n",
        "    print(f\"Checking filename: {filename}\")\n",
        "\n",
        "    #uses regex to search for angle of attack value, mach number, and reynolds number in the file\n",
        "    match = re.search(r'A(m?\\d*\\.\\d+|m?\\d+)_M([-+]?\\d*\\.\\d+|\\d+)_Re((?:\\d+\\.\\d+|\\d+)(?:e[+-]?\\d+)?)', filename, re.IGNORECASE)\n",
        "\n",
        "    if match:\n",
        "        aoa_value = match.group(1)\n",
        "        if aoa_value.startswith(\"m\"):\n",
        "            aoa_value = -float(aoa_value[1:]) #adds a negative sign to angle of attack values starting with 'm'\n",
        "        else:\n",
        "            aoa_value = float(aoa_value)\n",
        "\n",
        "        extracted_data = {\n",
        "            \"angle_of_attack\": aoa_value,\n",
        "            \"mach_number\": float(match.group(2)),\n",
        "            \"reynolds_number\": float(match.group(3)),\n",
        "            \"filename\": filename\n",
        "        }\n",
        "        print(f\"Extracted from {filename}: {extracted_data}\")\n",
        "        return extracted_data\n",
        "\n",
        "    print(f\"No match found for {filename}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Finds the best matching file based on the user's query parameters.\n",
        "\"\"\"\n",
        "def find_best_matching_file(query_params, file_dict, angle_score, mach_score, re_score):\n",
        "    best_matches = []\n",
        "    best_score = float('inf')\n",
        "\n",
        "    for subfolder, files in file_dict.items(): #check for score by subfolder\n",
        "        best_subfolder_score = float('inf')\n",
        "        best_subfolder_match = None\n",
        "        for filename, url in files.items():\n",
        "            metadata = extract_metadata_from_filename(filename)\n",
        "            if not metadata:\n",
        "                continue\n",
        "\n",
        "            angle_diff = abs(metadata[\"angle_of_attack\"] - query_params[\"Angle of Attack\"])\n",
        "            mach_diff = abs(metadata[\"mach_number\"] - query_params[\"Mach Number\"])\n",
        "            re_diff = abs(metadata[\"reynolds_number\"] - query_params[\"Reynolds Number\"])\n",
        "\n",
        "            if angle_diff < angle_score and mach_diff < mach_score and re_diff < re_score: #scores files based on similarity to query and how well it matches threshold\n",
        "                score = angle_diff + mach_diff + re_diff\n",
        "                if score <= best_subfolder_score:\n",
        "                    best_subfolder_match = (filename, url, subfolder)\n",
        "                    best_subfolder_score = score\n",
        "        if best_subfolder_match:\n",
        "            best_matches.append(best_subfolder_match)\n",
        "\n",
        "    if best_matches:\n",
        "        if len(best_matches) == 1:\n",
        "            filename, url, subfolder = best_matches[0]\n",
        "            print(f\"Best matching file found in {subfolder}: {filename}\")\n",
        "            return url, subfolder\n",
        "        else:\n",
        "            print(\"Multiple matching files found in different subfolders:\") #ask user which subfolder to use\n",
        "            for i, (filename, url, subfolder) in enumerate(best_matches, 1):\n",
        "                print(f\"{i}. {filename} in {subfolder}\")\n",
        "\n",
        "            choice = int(input(\"Enter the number of the subfolder you want to use: \")) - 1\n",
        "            if 0 <= choice < len(best_matches):\n",
        "                filename, url, subfolder = best_matches[choice]\n",
        "                print(f\"Selected file from {subfolder}: {filename}\")\n",
        "                return url, subfolder\n",
        "            else:\n",
        "                print(\"Invalid selection.\")\n",
        "                return None, None\n",
        "\n",
        "    print(\"No suitable file match found.\")\n",
        "    return None, None\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Downloads the airfoil data file and plots the Cp distribution.\n",
        "\"\"\"\n",
        "def download_and_plot_airfoil_data(file_url):\n",
        "\n",
        "    #downloads the best matching file\n",
        "    print(f\"Downloading file from: {file_url}\")\n",
        "    response = requests.get(file_url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error downloading file.\")\n",
        "        return\n",
        "\n",
        "    data = response.text.split(\"\\n\") #split the file by lines\n",
        "    data = data[1:] #skips the first line\n",
        "    data = [line.replace(',', ' ') for line in data if line.strip()] #removes commas from file\n",
        "\n",
        "    df = pd.DataFrame([line.split() for line in data], dtype=float) #creates a data frame object\n",
        "\n",
        "    df = df.iloc[:, :2] #only uses first two columns\n",
        "\n",
        "    #plots the data\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(df.iloc[:, 0], df.iloc[:, 1], marker='o', linestyle='-')\n",
        "    plt.xlabel(\"x/c\")\n",
        "    plt.ylabel(\"Cp\")\n",
        "    plt.title(\"Cp Distribution\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"\n",
        "predicts distribution of cp using LAM\n",
        "\"\"\"\n",
        "def predict_distribution(query_params, coordinates_file, lam_model, use_gpu):\n",
        "    print(\"predicting...\")\n",
        "    demo_num_points_per_surface = 120\n",
        "    input_airfoil = coordinates_file\n",
        "    angle_of_attack = query_params[\"Angle of Attack\"]\n",
        "    mach_number = query_params[\"Mach Number\"]\n",
        "    reynolds_number = query_params[\"Reynolds Number\"]\n",
        "    airfoil = lam_adapt.input_data(coordinates_file, angle_of_attack, mach_number, demo_num_points_per_surface, use_gpu=use_gpu)\n",
        "    predictions = lam_model.predict(airfoil, get_coeff=True)\n",
        "\n",
        "    # get prediction mean and standard deviation\n",
        "    prediction_mean = predictions['cp_distribution'].mean.cpu().detach().numpy()\n",
        "    prediction_sig = np.sqrt(np.diag(predictions['cp_distribution'].covariance_matrix.cpu().detach().numpy()))\n",
        "\n",
        "    # organize into upper and lower surfaces for plotting\n",
        "    f, ax = plt.subplots()\n",
        "    test_xcu, test_xcl = predictions['xc'][:demo_num_points_per_surface].cpu(), predictions['xc'][demo_num_points_per_surface:].cpu() # x/c\n",
        "    test_cpu, test_cpl = prediction_mean[:demo_num_points_per_surface], prediction_mean[demo_num_points_per_surface:] # C_p\n",
        "    test_2sigu, test_2sigl = 2*prediction_sig[:demo_num_points_per_surface], 2*prediction_sig[demo_num_points_per_surface:] # 2 sigma in C_p\n",
        "    plt.plot(test_xcu, test_cpu, 'r-', label='Predicted mean')\n",
        "    plt.plot(test_xcl, test_cpl, 'r-')\n",
        "    plt.fill_between(test_xcu, test_cpu-test_2sigu, test_cpu+test_2sigu, color='lightgray', label='Predicted 2$\\sigma$')\n",
        "    plt.fill_between(test_xcl, test_cpl-test_2sigl, test_cpl+test_2sigl, color='lightgray')\n",
        "    plt.xlabel('x/c')\n",
        "    plt.ylabel('$C_p$')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.legend()\n",
        "    plt.text(0.67, 0.7, '$c_l$ = ' + str(np.round(predictions['cl_mean'], 3)) + ' $\\pm$ ' + str(np.round(2*predictions['cl_stdev'], 3)), transform=ax.transAxes)\n",
        "    plt.text(0.67, 0.65, '$c_d$ = ' + str(np.round(predictions['cd_mean'], 3)) + ' $\\pm$ ' + str(np.round(2*predictions['cd_stdev'], 3)), transform=ax.transAxes)\n",
        "    plt.text(0.67, 0.6, '$c_m$ = ' + str(np.round(predictions['cm_mean'], 3)) + ' $\\pm$ ' + str(np.round(2*predictions['cm_stdev'], 3)), transform=ax.transAxes)\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"\n",
        "main loop for user interaction, prompts user for query and processes it until user exits\n",
        "\"\"\"\n",
        "def process_user_query():\n",
        "    qa_pipeline = load_bert_pipeline()\n",
        "    lam_model, use_gpu = load_lam_model()\n",
        "\n",
        "    print(\"The current thresholds for matching files are: 0.1 degree for angle of attack, 0.01 for mach number, and 1e5 for reynolds number.\")\n",
        "    keepThresholds = input(\"Do you want to change the thresholds? (yes/no): \").lower() #prompts user to change thresholds\n",
        "    if keepThresholds == \"yes\" or keepThresholds == \"y\":\n",
        "        angle_score = float(input(\"Enter new angle of attack threshold: \"))\n",
        "        mach_score = float(input(\"Enter new mach number threshold: \"))\n",
        "        re_score = float(input(\"Enter new reynolds number threshold: \"))\n",
        "    else:\n",
        "        angle_score = 0.1\n",
        "        mach_score = 0.01\n",
        "        re_score = 1e5\n",
        "    while True:\n",
        "        query = input(\"Enter your query (or type 'exit' to quit): \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        query_params = extract_query_parameters(query, qa_pipeline)\n",
        "        if not query_params or None in query_params.values():\n",
        "            print(\"Failed to extract parameters. Please try again.\")\n",
        "            continue\n",
        "\n",
        "        airfoil_name = query_params[\"Airfoil Name\"]\n",
        "        print(f\"Detected airfoil: {airfoil_name}\")\n",
        "\n",
        "        file_dict = get_airfoil_filenames(airfoil_name)\n",
        "        if not file_dict: #if airfoil is not in folder, prompts user to enter a csv if not a NACA airfoil\n",
        "            if(airfoil_name.upper().startswith(\"NACA\")):\n",
        "                print(\"Using LAM to predict distribution.\")\n",
        "                predict_distribution(query_params, airfoil_name.upper(), lam_model, use_gpu)\n",
        "                continue\n",
        "            print(\"Airfoil data not found. Enter a csv file of coordinates for prediction.\")\n",
        "            uploaded_files = files.upload()\n",
        "            user_file = list(uploaded_files.keys())[0]\n",
        "            print(\"Using LAM to predict distribution.\")\n",
        "            predict_distribution(query_params, user_file, lam_model, use_gpu)\n",
        "            continue\n",
        "\n",
        "        file_url, subfolder = find_best_matching_file(query_params, file_dict, angle_score, mach_score, re_score)\n",
        "        if not file_url:\n",
        "            print(\"No suitable file found. Using LAM to predict distribution.\") #if no file match in folder, uses LAM, prompts user for csv if no coordinates file present\n",
        "            subfolder = subfolder if subfolder else \"root\"\n",
        "            coordinates_file = get_airfoil_geometry(file_dict, subfolder)\n",
        "            if not coordinates_file:\n",
        "                if(airfoil_name.upper().startswith(\"NACA\")):\n",
        "                    print(\"Using LAM to predict distribution.\")\n",
        "                    predict_distribution(query_params, airfoil_name.upper(), lam_model, use_gpu)\n",
        "                    continue\n",
        "                print(\"Coordinates file not found. Enter a csv file of coordinates for prediction.\")\n",
        "                uploaded_files = files.upload()\n",
        "                user_file = list(uploaded_files.keys())[0]\n",
        "                predict_distribution(query_params, user_file, lam_model, use_gpu)\n",
        "                continue\n",
        "            predict_distribution(query_params, coordinates_file, lam_model, use_gpu)\n",
        "            continue\n",
        "\n",
        "        download_and_plot_airfoil_data(file_url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_user_query()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}